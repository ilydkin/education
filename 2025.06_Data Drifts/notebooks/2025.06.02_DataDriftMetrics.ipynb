{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Data Drifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "project = os.getenv('PROJECTPATH', None)\n",
    "if project:\n",
    "    sys.path.append(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skewnorm, entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, Layout, Dropdown\n",
    "from typing import Literal, Callable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_drift_metrics import PSI, Wasserstein, KS, JansenShannon, FeatureGeneratorWhithBins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Population Stability Index\n",
    "$$\n",
    "\\text{PSI} = \\sum_{i=1}^{n} \\left( \\text{Expected}_i - \\text{Actual}_i \\right) \\cdot \\ln \\left( \\frac{\\text{Expected}_i}{\\text{Actual}_i} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{PSI} \\in [0,\\ \\infty)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $Expected_i$ — mean in i-bin of train data\n",
    "- $Actual_i$ — mean in i-bin of current data\n",
    "- $n$ — number of bins\n",
    "\n",
    "Logic:\n",
    "- quantifies the distribution shift between two vectors by comparing their proportions across predefined bins\n",
    "- It is calculated using a logarithmic formula that emphasizes both magnitude and direction of change.\n",
    "- Binning is required, and the quality of the metric can depend on the number and boundaries of the bins.\n",
    "- PSI is particularly sensitive to small proportions\n",
    "\n",
    "Application in Evidently:\n",
    " - tabular data numerical and categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Wasserstein distance (Earth Mover's Distance)\n",
    "\n",
    "$$\n",
    "W_1^{\\text{norm}}(P, Q) = \\frac{1}{b - a} \\int_0^1 \\left| F_P^{-1}(u) - F_Q^{-1}(u) \\right| \\, du\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_1^{\\text{norm}}(P, Q) \\in [0,\\ 1]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $F_P^{-1}(u)$ — quantile function (inverse CDF) of the training dataset  \n",
    "- $F_Q^{-1}(u)$ — quantile function (inverse CDF) of the current dataset  \n",
    "- $u \\in [0, 1]$ — probability level  \n",
    "- $[a, b]$ — support range: from min to max across both distributions  \n",
    "- $W_1^{\\text{norm}}(P, Q)$ — normalized Wasserstein distance representing the average shift in quantiles, scaled by the support range\n",
    "\n",
    "Logic:\n",
    "- Measures the geometric distance between quantile functions (inverse CDFs) of two distributions\n",
    "- The normalized version divides the Wasserstein distance by the scale\n",
    "- Unlike PSI it does not require binning — it operates directly on continuous distributions via their CDFs.\n",
    "\n",
    "Application in Evidently:\n",
    " - only numerical\n",
    " - default method for numerical data, if > 1000 objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Kolmogorov–Smirnov\n",
    "$$\n",
    "D_{n,m} = \\sup_x \\left| F_n(x) - F_m(x) \\right|\n",
    "$$\n",
    "\n",
    "$$\n",
    "D_{n,m} \\in [0,\\ 1]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $F_n(x)$ — empirical cumulative distribution function (ECDF) the training dataset \n",
    "- $F_m(x)$ — ECDF of the **current** dataset (e.g., production data)  \n",
    "- $x$ — any value within the combined domain of both datasets\n",
    "- $D_{n,m}$ — the maximum vertical distance between the two ECDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Jensen–Shannon distance\n",
    "1. **Entropy**: \n",
    "    $$ H(p) = -\\sum_i p_ilog_2(p_i) $$\n",
    "    \n",
    "    where:\n",
    "    - $p$ is a probability of event $i$\n",
    "    \n",
    "    **intuition**: \n",
    "    - entropy is the expected value of information\n",
    "#\n",
    "\n",
    "2. **Cross Entropy**:\n",
    "    $$ H(p, q) = -\\sum_i p_ilog_2(q_i) $$\n",
    "    \n",
    "    where:\n",
    "    - $p$ is the true distribution  \n",
    "    - $q$ is the estimated (model) distribution  \n",
    "    \n",
    "    **intuition**\n",
    "    - How many bits are needed to encode events from $p$ using $q$ \n",
    "#\n",
    "\n",
    "3. **KLD Kullback–Leibler Divergence**:\n",
    "    $$ D_{\\mathrm{KL}}(p \\parallel q) = \\sum_i p_ilog_2(\\frac{p_i}{q_i})$$\n",
    "    $$ = \\sum_i p_ilog_2(p_i) -\\sum_i p_ilog_2(q_i)$$\n",
    "    $$ = H(p,q) - H(p)$$\n",
    "    \n",
    "    **intuition**:\n",
    "    - Kullback–Leibler Divergence measures the difference between Cross Entropy and Entropy. \n",
    "    - It equals zero only when the two distributions are identical, and is strictly positive otherwise.\n",
    "#\n",
    "\n",
    "4. **Mixture Distribution**:\n",
    "    $$ \\vec{m} = \\frac{\\vec{p} + \\vec{q}}{2} $$\n",
    "    \n",
    "    **intuition**:\n",
    "    - $\\vec{m}$ is the average (mixture) distribution  \n",
    "    - acts as a symmetric reference between $\\vec{p}$ and $\\vec{q}$ \n",
    "#\n",
    "5. **Jensen–Shannon Divergence**:\n",
    "    $$D_{\\mathrm{JS}}(\\vec{p} \\parallel \\vec{q}) = \\frac{D_{\\mathrm{KL}}(\\vec{p} \\parallel \\vec{m}) + D_{\\mathrm{KL}}(\\vec{q} \\parallel \\vec{m})}{2}$$\n",
    "    where:\n",
    "    - $\\vec{m}$ is the mixture distribution  \n",
    "    \n",
    "    **intuition**: \n",
    "    - symmetric, smoothed version of KL Divergence \n",
    "    - avoids infinite values and handles zero probabilities gracefully\n",
    "#\n",
    "6. **Jensen–Shannon Distance**:\n",
    "    $$ \\text{Jensen–Shannon distance} = \\sqrt{D_{\\mathrm{JS}}(\\vec{p} \\parallel \\vec{q})} $$\n",
    "\n",
    "    **Properties**: \n",
    "    - The metric lies within the range [0, 1] and is symmetric\n",
    "    \n",
    "    **Intuition**: \n",
    "    - When calculating KLD, we took base-2 logarithms of probabilities in [0, 1], which is similar to squaring.\n",
    "    - Taking the square root brings the values back into the [0, 1] range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Visualizer:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.psi = PSI(**kwargs)\n",
    "        self.wass = Wasserstein(**kwargs)\n",
    "        self.ks = KS(**kwargs)\n",
    "        self.jsd = JansenShannon(**kwargs) \n",
    "\n",
    "    def plot_psi(self, ax: Axes):\n",
    "        ax.bar([\"PSI\"], [self.psi.value], color='skyblue')\n",
    "        ax.set_ylim(-0.5, 50)\n",
    "        ax.axhline(0.25, color='red', linestyle='--', label='PSI = 0.25 - порог значительного дрифта')\n",
    "        ax.text(0, self.psi.value + 0.2, f'{self.psi.value:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold', color='black')\n",
    "        ax.set_title(\"PSI (Population Stability Index)\")\n",
    "        ax.set_ylim(0, 20)\n",
    "        ax.legend()\n",
    "\n",
    "    def plot_psi_bins (self, ax: Axes):\n",
    "        bin_centers = (self.psi.bins[:-1] + self.psi.bins[1:]) / 2\n",
    "        width = (self.psi.bins[1] - self.psi.bins[0]) * 0.4  # ширина столбиков\n",
    "        ax.bar(bin_centers - width / 2, self.psi.train_ratio, width=width, label='Train', alpha=0.7, color='skyblue')\n",
    "        ax.bar(bin_centers + width / 2, self.psi.current_ratio, width=width, label='Current', alpha=0.7, color='orange')\n",
    "        ax.plot(bin_centers, self.psi.bins_contribution, label='PSI Contribution', color='purple', linewidth=2.5, marker='o', markersize=6)\n",
    "        ax.set_title(\"Доли по бинам (для PSI)\")\n",
    "        ax.set_xlabel(\"Значения признака (по бинам)\")\n",
    "        ax.set_ylabel(\"Доля наблюдений\")\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        ax.legend()\n",
    "    \n",
    "    def plot_js (self, ax: Axes):\n",
    "        ax.bar([\"JSD\"], [self.jsd.value], color='lightgreen')\n",
    "        ax.axhline(0, color='gray', linestyle='--')\n",
    "        ax.axhline(0.1, color='red', linestyle='--', label='JSD = 0.1 - порог статистической значимости')\n",
    "        ax.text(0, self.jsd.value + 0.02, f'{self.jsd.value:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold', color='black')\n",
    "        ax.set_title(\"Jensen-Shannon Distance\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.legend()\n",
    "    \n",
    "    def plot_jsd_bins (self, ax: Axes):\n",
    "        bin_centers = (self.jsd.bins[:-1] + self.jsd.bins[1:]) / 2\n",
    "        width = (self.jsd.bins[1] - self.jsd.bins[0]) * 0.4  \n",
    "        ax.bar(bin_centers - width / 2, self.jsd.train_ratio, width=width, label='Train', alpha=0.5, color='skyblue')\n",
    "        ax.bar(bin_centers + width / 2, self.jsd.current_ratio, width=width, label='Current', alpha=0.5, color='orange')\n",
    "        ax.plot(bin_centers, self.jsd.jsd_contrib, label='JSD Contribution', color='purple', linewidth=2.5, marker='o', markersize=6)\n",
    "        ax.set_title(\"Вклад каждого бина в Jensen–Shannon Divergence\")\n",
    "        ax.set_xlabel(\"Значения признака (по бинам)\")\n",
    "        ax.set_ylabel(\"Вклад в дивергенцию\")\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        ax.legend()\n",
    "\n",
    "    def plot_wasserstein (self,  ax: Axes):\n",
    "        ax.bar([\"W1\"], [self.wass.value], color='lightgreen')\n",
    "        ax.axhline(0, color='gray', linestyle='--')\n",
    "        ax.axhline(0.1, color='red', linestyle='--', label='EMD = 0.1 - порог значительного дрифта')\n",
    "        ax.text(0, self.wass.value + 0.02, f'{self.wass.value:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold', color='black')\n",
    "        ax.set_title(\"W1 (Wasserstein distance) / EMD (Earth Mover's Distance)\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.legend()\n",
    "    \n",
    "    def plot_wasserstein_geom (self, ax: Axes):       \n",
    "        ax.plot(self.wass.common_x, self.wass.train_iecdf, label='Train IECDF', color='blue')\n",
    "        ax.plot(self.wass.common_x, self.wass.current_iecdf, label='Current IECDF', color='orange')\n",
    "        ax.fill_between(self.wass.common_x, self.wass.train_iecdf, self.wass.current_iecdf, color='lightcoral', alpha=0.4, label='|Train - Current|')\n",
    "        ax.set_title(\"Разность IECDF двух выборок\")\n",
    "        ax.set_xlabel(\"Probability (quantiles)\")\n",
    "        ax.set_ylabel(\"Feature value\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    def plot_ks (self, ax: Axes):\n",
    "        ax.bar([\"KS\"], [self.ks.value], color='lightgreen')\n",
    "        ax.plot([\"KS\"], [self.ks.p_value], marker='o', color='purple', markersize=8, label='p-value')\n",
    "        ax.axhline(0, color='gray', linestyle='--')\n",
    "        ax.axhline(0.05, color='red', linestyle='--', label='P-value = 0.05 - порог статистической значимости')\n",
    "        ax.text(0, self.ks.value + 0.02, f'{self.ks.value:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold', color='black')\n",
    "        ax.text(0, float(self.ks.p_value) + 0.02, f'{self.ks.p_value:.2e}', ha='center', va='bottom', fontsize=9, fontweight='bold', color='purple')\n",
    "        ax.set_title(\"KS Kolmogorov-Smirnov\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.legend()\n",
    "\n",
    "    def plot_ks_geom (self, ax: Axes):       \n",
    "        ax.plot(self.ks.all_uniques, self.ks.train_ecfd, label='Train ECDF', color='blue')\n",
    "        ax.plot(self.ks.all_uniques, self.ks.current_ecfd, label='Current ECDF', color='orange')\n",
    "        ax.fill_between(self.ks.all_uniques, self.ks.train_ecfd, self.ks.current_ecfd, color='lightcoral', alpha=0.4, label='|Train - Current|')\n",
    "        ax.set_title(\"Разность ECDF двух выборок\")\n",
    "        ax.set_xlabel(\"Значения фичи (нормализованные)\")\n",
    "        ax.set_ylabel(\"Probability\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "    \n",
    "    def visualize (self, **kwargs):\n",
    "        \"\"\" \n",
    "        Функция визуализации\n",
    "        \"\"\"\n",
    "        _, axs = plt.subplots(\n",
    "            nrows = 4,\n",
    "            ncols= 2, \n",
    "            figsize=(12, 15), \n",
    "            gridspec_kw={\"width_ratios\": [1, 1.5]},\n",
    "            constrained_layout=True\n",
    "        )\n",
    "\n",
    "        # Ряд 1: PSI\n",
    "        ax1, ax2 = axs[0]\n",
    "        self.plot_psi(ax1)\n",
    "        self.plot_psi_bins(ax2)\n",
    "        \n",
    "        # Ряд 2: Jensen-Shennon\n",
    "        ax3, ax4 = axs[1]\n",
    "        self.plot_js(ax3)\n",
    "        self.plot_jsd_bins(ax4)\n",
    "\n",
    "        # Ряд 3: Wasserstein\n",
    "        ax5, ax6 = axs[2]\n",
    "        self.plot_wasserstein(ax5)\n",
    "        self.plot_wasserstein_geom(ax6)\n",
    "\n",
    "        # Ряд 3: Колмогоров-Смирнов\n",
    "        ax7, ax8 = axs[3]\n",
    "        self.plot_ks(ax7)\n",
    "        self.plot_ks_geom(ax8)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf18e01f3954f1285b99ee4ad09ef2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Распределение:', index=1, options=('normal', 'skewed'), value='ske…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.run_visualizer(**kwargs)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Layout(width='1000px')\n",
    "style = {'description_width': '200px'}\n",
    "\n",
    "def run_visualizer (**kwargs):\n",
    "    viz = Visualizer(**kwargs)\n",
    "    return viz.visualize(**kwargs)\n",
    "\n",
    "interact(\n",
    "    run_visualizer,\n",
    "    distribution = Dropdown(options=['normal', 'skewed'], value='skewed', description='Распределение:'),\n",
    "    skew = IntSlider(value=10, min=-10, max=10, step=1, description='Смещение распределения', layout = l, style = style),\n",
    "\n",
    "    n_batches = IntSlider(value=50, min=5, max=100, step=1, description='ЧИСЛО БИНОВ', layout = l, style = style),\n",
    "    \n",
    "    train_size = IntSlider(value=20000, min=1000, max=100000, step=100, description='TRAIN: размер выборки', layout = l, style = style),\n",
    "    current_size = IntSlider(value=3500, min=1000, max=100000, step=100, description='CURRENT: размер выборки', layout = l, style = style),\n",
    "    \n",
    "    train_mean = FloatSlider(value=35.0, min=0, max=100.0, step=1.0, description='TRAIN: среднее', layout = l, style = style),\n",
    "    current_mean = FloatSlider(value=30.0, min=0, max=100.0, step=1.0, description='CURRENT: среднее', layout = l, style = style),\n",
    "    \n",
    "    train_std = FloatSlider(value=5.0, min=0.01, max=10.0, step=0.1, description='TRAIN: стандартное отклонение', layout = l, style = style),\n",
    "    current_std = FloatSlider(value=5.2, min=0.01, max=10.0, step=0.1, description='CURRENT: стандартное отклонение', layout = l, style = style),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"distribution\": \"normal\",\n",
    "    \"n_batches\": 50, \n",
    "    \"train_size\": 10000, \n",
    "    \"current_size\": 10000, \n",
    "    \"train_mean\": 5, \n",
    "    \"current_mean\": 5, \n",
    "    \"train_std\": 5, \n",
    "    \"current_std\": 5, \n",
    "}\n",
    "data= FeatureGeneratorWhithBins(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.0, -2.321928094887362, -3.321928094887362)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(0.25, 2), math.log(0.2, 2), math.log(0.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "энтропия: -((0.500001 * -0.9999971146128036) + (0.499999 * -1.0000028853929672)) = 0.9999999999971146\n",
      "кросс-энтропия: -((0.500001 * -1.0) + (0.499999 * -1.0)) = 1.0\n",
      "дельта после логарифмирования: 0.0\n",
      "дельта: 2.8853871963940847e-06\n",
      "дельта: 2.8853871963940847e-06\n"
     ]
    }
   ],
   "source": [
    "a = 0.500001\n",
    "b = 0.499999\n",
    "\n",
    "c = 0.5\n",
    "d = 0.5\n",
    "\n",
    "if a + b > 1 or c + d > 1:\n",
    "    raise ValueError('Сумма вероятностей не может превышать 1')\n",
    "a_log = math.log(a, 2)\n",
    "b_log = math.log(b, 2)\n",
    "c_log = math.log(c, 2)\n",
    "d_log = math.log(d, 2)\n",
    "print (f\"энтропия: -(({a} * {a_log}) + ({b} * {b_log})) = {-1*(a*a_log + b*b_log)}\")\n",
    "print (f\"кросс-энтропия: -(({a} * {c_log}) + ({b} * {d_log})) = {-1*(a*c_log + b*d_log)}\")\n",
    "print (f\"дельта после логарифмирования: {abs(c_log - d_log)}\")\n",
    "\n",
    "print (f\"дельта: {a_log - c_log}\")\n",
    "print (f\"дельта: {a_log - d_log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
